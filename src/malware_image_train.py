from load_images import *
from extract_features import *
from skimage import transform
from sklearn import svm


def train(dataset_path):
    image_list = prefetch_images(dataset_path)

    if len(image_list) <= 0:
        return

    features = {} # dictionary<family name, list of feature vector>
    for i in range(len(image_list)):
        family = image_list[i][0]
        images = image_list[i][1]
        print("fetching...", family)
        hist_range = 256
        for j in range(len(images)):
            image_path = dataset_path + family + '/' + images[j]
            print(image_path, j, "out of", len(images))
            img = io.imread(image_path)

            # Feature 1: horizontal edge: 1 x 256
            hist = project_h_edge(img, gauss_sigma=9, print_img=False, total_blocks=hist_range)

            # resize to desired length. e.g. 256
            hist_arr = np.array(hist).reshape(1, len(hist))
            hist = transform.resize(hist_arr, (1, hist_range), mode='reflect').tolist()[0]

            # Feature 2: Histogram of Gaussian
            hog_feature = extract_HOG(img, blocks=(12, 12)).tolist()
            mmax, mmin = 0, 0
            for k in range(len(hog_feature)):
                mmax = max(mmax, hog_feature[k])
                mmin = min(mmin, hog_feature[k])
            for k in range(len(hog_feature)):
                hog_feature[k] = (hog_feature[k] - mmin) * 255 / (mmax - mmin)
            hog_feature = [sum(hog_feature) / len(hog_feature)]

            # ---------------------------
            # if not using mean value, the dimension would be 8100
            # ---------------------------

            # Feature 3: Mean intensity of each grid
            grids = extract_grid_blocks(img)
            mean_vec = means_feature(grids)

            # Feature 4: LBP
            lbp_hist = extract_lbp_feature(img)

            # Feature 5: Histogram(Contrast)
            contrast_hist = histogram_feature(img)

            # Feature 6: Media images (flatten)
            median_vec = median_feature(img)

            feature_vec = hist + hog_feature + mean_vec + lbp_hist + contrast_hist + median_vec

            if family not in features:
                features[family] = list()
            l = features.get(family)
            l.append(feature_vec)

    # N-fold cross-validation
    num_fold = 5
    accuracy = [0] * num_fold
    for q in range(num_fold):
        training_set = list()
        training_labels = list()
        testing_set = list()
        testing_labels = list()
        for family in features:
            feature_mat = features.get(family)
            print(family, "sample size:", len(feature_mat))

            fold_start = q * int(len(feature_mat) / num_fold)
            fold_end = fold_start + int(len(feature_mat) / num_fold) - 1

            for j in range(len(feature_mat)):
                if fold_start <= j <= fold_end:
                    testing_set.append(feature_mat[j])
                    testing_labels.append(family)
                else:
                    training_set.append(feature_mat[j])
                    training_labels.append(family)

        clf = svm.SVC()
        clf.fit(training_set, training_labels)

        # testing phase
        print("testing...")
        p_res = clf.predict(testing_set)

        accuracy[q] = 0
        for i in range(len(p_res)):
            if p_res[i] == testing_labels[i]:
                accuracy[q] += 1
        accuracy[q] = (accuracy[q] / len(p_res)) * 100
        print(accuracy[q])

    print(accuracy)

