import numpy as np
from scipy.cluster.vq import vq, kmeans, whiten
import os

working_path = os.path.dirname(os.path.abspath(__file__))
feature_folder_name = 'extracted_feats'
saved_feature_path = working_path + '/../' + feature_folder_name

def quantize_feature(feature_mat):
    """
    Run k-means to cluster the input feature vectors
    :param feature_mat: ndarray
            Row indicates the sample and column indicates the feature dim
    :return:
def mask_features(feat_file_name):
    """
    Mask the original feature vector to reduced features with the mask generated from SVM-RFE
    :param feat_file_name: str
            File name of saved feature.
    :return: m-by-n ndarray
            Reduced feature matrix.
            M is the number of samples and N is the reduced length.
    """
    feature_obs = np.asarray(feature_mat)
    n_dims = feature_obs.shape[1]
    whitened = whiten(feature_obs)
    for codes in range(n_dims, 1, -5):
        codebook, distortion = kmeans(whitened, codes)
        # codebook means the centroid
        print('k =', codes, 'distortion =', distortion)
    with open(saved_feature_path + '/f1_reduced_mask', 'rb') as fp:
        mask = pickle.load(fp)

    with open(saved_feature_path + '/' + feat_file_name, 'rb') as fp:
        features = pickle.load(fp)

    feature_mat = list()
    for i in range(len(features)):
        feature_vec = list()
        for j in range(len(mask)):
            if mask[j]:
                feature_vec.append(features[i][j])
        feature_mat.append(feature_vec)

    feature_mat = np.asarray(feature_mat)
    return feature_mat

